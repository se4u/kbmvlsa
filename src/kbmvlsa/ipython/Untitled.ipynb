{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "20\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'predictions_fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-746f2ba78623>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0mmodel_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqid_2_true_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqid_2_fsdm_top_100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity_vec_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmvlsa_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqid_2_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     predictions_fn = test_model(test_ent, qid_2_fsdm_top_100, entity_vec_dict, mvlsa_data, qid_2_query, qid_2_true_answer,\n\u001b[0;32m--> 190\u001b[0;31m                              model_fn=model_fn)\n\u001b[0m\u001b[1;32m    191\u001b[0m     \u001b[0;32mimport\u001b[0m \u001b[0mpdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-746f2ba78623>\u001b[0m in \u001b[0;36mtest_model\u001b[0;34m(testing_query_ids, entities_retrieved_by_fsdm, entity_vec_dict, mvlsa_data, query_id_to_question_tokens, true_answer_entities, model_fn, test_data_fn, prediction_fn)\u001b[0m\n\u001b[1;32m    173\u001b[0m                                               mvlsa_data))))\n\u001b[1;32m    174\u001b[0m     \u001b[0;31m# os.system('~/data/svm_rank/svm_rank_classify %s %s %s'%(test_data_fn, model_fn, prediction_fn))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredictions_fn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_query_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_answer_entities\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'predictions_fn' is not defined"
     ]
    }
   ],
   "source": [
    "# %load eval.py\n",
    "#!/usr/bin/env python\n",
    "'''\n",
    "| Filename    : eval.py\n",
    "| Description :\n",
    "| Author      : Pushpendre Rastogi\n",
    "| Created     : Thu Dec  1 20:46:46 2016 (-0500)\n",
    "| Last-Updated: Fri Dec  2 06:27:32 2016 (-0500)\n",
    "|           By: Pushpendre Rastogi\n",
    "|     Update #: 23\n",
    "All learning to rank methods are quite simple, the goal is to learn a model\n",
    "that can optimize a metric like MAP, or ROC given a few examples. In my case\n",
    "I can start with a list of things that the true FSDM code returns, thanks to\n",
    "chenyan's results files, and then rerank those things.\n",
    "'''\n",
    "import config\n",
    "import numpy\n",
    "from collections import defaultdict, OrderedDict\n",
    "import cPickle as pkl\n",
    "import os, itertools\n",
    "DBPEDIA_PFXLEN = len('http://dbpedia.org/resource/')\n",
    "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n",
    "qid_2_query = {}\n",
    "with open(config.QUERY_FN) as file_handle:\n",
    "    for (qid, query_string) in (row.strip().split('\\t') for row in file_handle):\n",
    "        qid_2_query[qid] = query_string.split()\n",
    "\n",
    "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-##-#-#-#-#\n",
    "qid_2_fsdm_top_100 = OrderedDict()\n",
    "with open(config.RANK_SVM_INEX_LD) as file_handle:\n",
    "    for (qid, _, answer, _serial_no, _score, __) in (\n",
    "            row.strip().split() for row in file_handle):\n",
    "        try:\n",
    "            qid_2_fsdm_top_100[qid].append(answer)\n",
    "        except KeyError:\n",
    "            qid_2_fsdm_top_100[qid] = [answer]\n",
    "            pass\n",
    "        pass\n",
    "    qid_2_fsdm_top_100.default_factory = None\n",
    "\n",
    "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n",
    "qid_2_true_answer = defaultdict(list)\n",
    "with open(config.QRELS_FN) as file_handle:\n",
    "    for (qid, _, answer, __) in (row.strip().split() for row in file_handle):\n",
    "        qid_2_true_answer[qid].append(answer)\n",
    "qid_2_true_answer.default_factory = None\n",
    "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n",
    "class FoldIterator(object):\n",
    "    def __init__(self, n=5, list_to_fold=None, total=None, return_iterables=False):\n",
    "        assert not (list_to_fold is None and total is None)\n",
    "        if total is None:\n",
    "            total=len(list_to_fold)\n",
    "        assert total == len(list_to_fold)\n",
    "        assert total%n == 0, \"Can not split %d into %d parts\"%(total, n)\n",
    "        self.n = n\n",
    "        self.i = 0\n",
    "        self.d = total / n\n",
    "        self.total = total\n",
    "        self.return_iterables = return_iterables\n",
    "        self.list_to_fold = list(list_to_fold)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def next(self):\n",
    "        if self.i == self.n:\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            test_start = self.i * self.d\n",
    "            test_end = test_start + self.d\n",
    "            if self.list_to_fold is not None:\n",
    "                if self.return_iterables:\n",
    "                    return ((self.list_to_fold[e] for e in itertools.chain(xrange(0, test_start), xrange(test_end, self.n))),# Train id\n",
    "                            (self.list_to_fold[e] for e in xrange(test_start, test_end))) # Test id\n",
    "                else:\n",
    "                    return ([self.list_to_fold[e] for e in (range(0, test_start) + range(test_end, self.total))],\n",
    "                            [self.list_to_fold[e] for e in range(test_start, test_end)])\n",
    "            else:\n",
    "                if self.return_iterables:\n",
    "                    return (itertools.chain(xrange(0, test_start), xrange(test_end, self.n)),# Train id\n",
    "                            xrange(test_start, test_end)) # Test id\n",
    "                else:\n",
    "                    return ((range(0, test_start) + range(test_end, self.total)),\n",
    "                            range(test_start, test_end))\n",
    "            pass\n",
    "        pass\n",
    "\n",
    "\n",
    "#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#\n",
    "def get_query_vec(query_token_list, mvlsa_word_emb_data):\n",
    "    # TODO: The real program should do these things automatically. For now\n",
    "    # I have manually made these changes to the query files.\n",
    "    # 1. Taking care of apostrophes, remove traling aprostrophes\n",
    "    # 2. Splitting hyphens\n",
    "    # 3. Removing other punctuation\n",
    "    def get_vec(token):\n",
    "        if token in mvlsa_word_emb_data:\n",
    "            return mvlsa_word_emb_data[token]\n",
    "        else:\n",
    "            return None\n",
    "        pass\n",
    "    query_vec = [get_vec(token) for token in query_token_list]\n",
    "    filtered_vec = [e for e in query_vec if e is not None]\n",
    "    if len(filtered_vec) > 0:\n",
    "        return numpy.mean(filtered_vec, axis=0)\n",
    "    else:\n",
    "        return numpy.zeros((300,))\n",
    "\n",
    "\n",
    "def feat_string(query_vec, answer_vec):\n",
    "    # TODO: Add customization to vary the features used.\n",
    "    vec = numpy.outer(query_vec[:25], answer_vec[:25]).ravel() * 1000\n",
    "    assert not numpy.isnan(vec).any()\n",
    "    return ''.join('%d:%.3e '%(i+1,e) for i,e in enumerate(vec))\n",
    "\n",
    "def train_model(training_query_ids, true_answer_entities, entities_retrieved_by_fsdm, entity_vec_dict, mvlsa_data, query_id_to_question_tokens,\n",
    "                train_data_fn = '/tmp/train_data_fn',\n",
    "                model_fn = '/tmp/model_fn'):\n",
    "    '''\n",
    "    --- INPUT ---\n",
    "    training_query_ids          : [INEX_LD-2009022', ...]\n",
    "    true_answer_entities        : {'INEX_LD-2009022': ['http://dbpedia.org/resource/Indian_Chinese_cuisine', ...], ...}\n",
    "    entities_retrieved_by_fsdm  : {'INEX_LD-2009022': ['http://dbpedia.org/resource/National_dish', ...], ...}\n",
    "    entity_vec_dict             : {'http://dbpedia.org/resource/National_dish': [300d 'float64' array]], ...}\n",
    "    mvlsa_data                  : {'star': [300d 'float64' array]}\n",
    "    query_id_to_question_tokens : {'INEX_LD-2009022': ['Szechwan', 'dish', 'food', 'cuisine']}\n",
    "    '''\n",
    "    with open(train_data_fn, 'wb') as train_data_f:\n",
    "        for numeric_qid, qid in enumerate(training_query_ids):\n",
    "            numeric_qid += 1\n",
    "            query_vec = get_query_vec(query_id_to_question_tokens[qid], mvlsa_data)\n",
    "            true_answer_set = set(true_answer_entities[qid])\n",
    "            for answer in true_answer_set:\n",
    "                train_data_f.write('1 qid:%d %s\\n'%(\n",
    "                    numeric_qid,\n",
    "                    feat_string(query_vec,\n",
    "                                get_query_vec(answer[DBPEDIA_PFXLEN:].strip().split('_'),\n",
    "                                              mvlsa_data))))\n",
    "\n",
    "            for answer in entities_retrieved_by_fsdm[qid]:\n",
    "                if answer not in true_answer_set:\n",
    "                    train_data_f.write('0 qid:%d %s\\n'%(\n",
    "                        numeric_qid,\n",
    "                        feat_string(query_vec,\n",
    "                                    get_query_vec(answer[DBPEDIA_PFXLEN:].split('_'),\n",
    "                                                  mvlsa_data))))\n",
    "\n",
    "    # os.system('~/data/svm_rank/svm_rank_learn -c 10 %s %s'%(train_data_fn, model_fn))\n",
    "    return model_fn\n",
    "\n",
    "def test_model(testing_query_ids, entities_retrieved_by_fsdm, entity_vec_dict, mvlsa_data, query_id_to_question_tokens, true_answer_entities,\n",
    "               model_fn = '/tmp/model_fn', test_data_fn='/tmp/test_data_fn', prediction_fn='/tmp/prediction_fn'):\n",
    "    '''\n",
    "    --- INPUT ---\n",
    "    testing_query_ids           :\n",
    "    entities_retrieved_by_fsdm  :\n",
    "    entity_vec_dict             :\n",
    "    mvlsa_data                  :\n",
    "    query_id_to_question_tokens :\n",
    "    --- OUTPUT ---\n",
    "    '''\n",
    "    with open(test_data_fn, 'wb') as test_data_f:\n",
    "        for numeric_qid, qid in enumerate(testing_query_ids):\n",
    "            numeric_qid += 1\n",
    "            query_vec = get_query_vec(query_id_to_question_tokens[qid], mvlsa_data)\n",
    "            true_answer_set = set(true_answer_entities[qid])\n",
    "            for answer in entities_retrieved_by_fsdm[qid]:\n",
    "                test_data_f.write('%d qid:%d %s\\n'%(\n",
    "                    int(answer in true_answer_set),\n",
    "                    numeric_qid,\n",
    "                    feat_string(query_vec,\n",
    "                                get_query_vec(answer[DBPEDIA_PFXLEN:].split('_'),\n",
    "                                              mvlsa_data))))\n",
    "    # os.system('~/data/svm_rank/svm_rank_classify %s %s %s'%(test_data_fn, model_fn, prediction_fn))\n",
    "    return predictions_fn\n",
    "\n",
    "def evaluate(test_query_ids, true_answer_entities, predictions):\n",
    "\n",
    "    print 'MAP', 'P@10', 'P@20'\n",
    "\n",
    "\n",
    "mvlsa_data = pkl.load(open(config.MVLSA_EMB_PKL_FN, mode=\"rb\"))\n",
    "# entity_vec_dict = pkl.load(open(\"kbmvlsa_embedding.pkl\", mode=\"rb\"))\n",
    "entity_vec_dict = defaultdict(float)\n",
    "for (train_ent, test_ent) in FoldIterator(n=5, list_to_fold=qid_2_fsdm_top_100):\n",
    "    print(len(train_ent))\n",
    "    print(len(test_ent))\n",
    "    model_fn = train_model(train_ent, qid_2_true_answer, qid_2_fsdm_top_100, entity_vec_dict, mvlsa_data, qid_2_query)\n",
    "    predictions_fn = test_model(test_ent, qid_2_fsdm_top_100, entity_vec_dict, mvlsa_data, qid_2_query, qid_2_true_answer,\n",
    "                             model_fn=model_fn)\n",
    "    import pdb\n",
    "    pdb.set_trace()\n",
    "    print(evaluate(test_ent, qid_2_true_answer, predictions_fn))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
