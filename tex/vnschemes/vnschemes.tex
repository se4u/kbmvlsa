\documentclass{tufte-handout}
% -------- %
% Packages %
% -------- %
% \usepackage[T1]{fontenc}
\usepackage{graphicx,amsmath,amssymb,url,xspace,booktabs,xcolor}
% tex.stackexchange.com/questions/2291/
% how-do-i-change-the-enumerate-list-format-to-use-letters-instead-of-the-defaul#comment3172_2294
\usepackage[shortlabels]{enumitem}
% tex.stackexchange.com/questions/171803/
% change-font-size-of-the-verbatim-environment
\usepackage{fancyvrb}
\usepackage{microtype}
\usepackage[acronym]{glossaries}
\usepackage[]{todonotes} % insert [disable] to disable all notes.
\usepackage{array}

% http://tex.stackexchange.com/questions/121601
% automatically-wrap-the-text-in-verbatim
\usepackage{listings}
\lstset{basicstyle=\small\ttfamily,%
  columns=flexible,%
  breaklines=true,%
  linewidth=17cm,%
  xleftmargin=-1cm,%
  xrightmargin=-1cm}
\newcolumntype{C}{>{$}c<{$}}
\newcolumntype{L}{>{$}l<{$}}
\newcolumntype{R}{>{$}r<{$}}
% -------- %
% Commands %
% -------- %
% Color Me Red
\newcommand{\cmr}[1]{{\color{red} #1}}
\newcommand{\note}[1]{\todo[author=Pushpendre,color=blue!40,size=\small,fancyline,inline]{#1}}
\newcommand{\Todo}[1]{\todo[author=Pushpendre,size=\small,inline]{#1}}
\newcommand{\eg}{e.g.,\xspace}
\newcommand{\bigeg}{E.g.,\xspace}
\newcommand{\etal}{\textit{et~al.\xspace}}
\newcommand{\etc}{etc.\@\xspace}
\newcommand{\ie}{i.e.,\xspace}
\newcommand{\bigie}{I.e.,\xspace}
\renewcommand{\cite}[1]{\textcolor{red}{#1}}
\newcommand{\alert}[1]{\textcolor{red}{#1}}
\newcommand{\remove}[1]{} % Change to {\remove}[0]{} to bring back
\title{Vertex Classification and Edge Prediction in high precision, low recall Graphs}
\author{Pushpendre Rastogi}
% ----------------------- %
% Document Class Settings %
% ----------------------- %
\IfFileExists{bergamo.sty}{\usepackage[osf]{bergamo}}{}% Bembo
\IfFileExists{chantill.sty}{\usepackage{chantill}}{}% Gill Sans
\setcaptionfont{%
\color{blue}% <-- set color here
}
% --------------------------------------- %
% Reset the table and figure environments %
% --------------------------------------- %
\makeatletter
\renewenvironment{figure}[1][htbp]{%
\@tufte@orig@float{figure}[#1]}{%
\@tufte@orig@endfloat}%
\renewenvironment{table}[1][htbp]{%
\@tufte@orig@float{table}[#1]}{%
\@tufte@orig@endfloat}%
\makeatother

\begin{document}
\maketitle
\section{Introduction}
\label{sec:introduction}
Consider a graph $G$ with ``labeled'' vertices and ``labeled'' edges
that has been constructed through a ``high precision-low recall'' process.
In other words,
the labeled edges present in the graph are highly likely to be correct
but the abscence of a labeled edge between two vertices is not a definitive
indicator of the lack of a relationship between those two vertices.
Similarly, the abscence of a vertex label is not a definitive indicator
that the vertex is truly unlabeled, it is possible that the label information
is simply missing.

The following problems commonly need to be solved while doing
inference over such graphs:
\begin{description}
\item[Vertex Label Prediction] Here the goal is to rank the nodes with unobserved
  labels such that the nodes with a particular true label appear first in the
  list. This task was called, \textit{Vertex Nomination} by \cite{fishkind2015vertex}
  \note{Give example.}, \textit{Class(Labeled) Instance Acquisition} by
  \cite{talukdar2010experiments,van2008finding}.
  A slightly different version of
  this task arises if we try to infer the label of
  an unlabeled vertex in isolation.
  It is also called \textit{Collective Classification}~\cite{sen2008collective}.
  A closely related task is \textit{Link based Clustering}.
\item[Edge Prediction] Here the goal is to predict what type of edge should two
  vertices be connected with if any. When the dataset is a knowledge graph
  then this task is commonly termed as knowledge base
  completion~\cite{nickel2016review}. This problem is also
  termed~\textit{Link Prediction}~\cite{liben2007link}.
  \todo{Slightly different formulations of the edge prediction task.}
\end{description}
As is clear from the plethora of terminology these two types of problem arise in
many different fields. Importantly, in this paper, these problems have been
treated completely separately, with a different set of techniques applied for
solving them.\todo{Not True! \cite{nickel2011three} says, ``Collective
  classification can be cast as a subtask of link prediction, as the class of
  an entity can be modelled by introducing a class relation and including the
  classes as entities in the tensor.''}
In this paper we show that the two closely problems can in fact be
reduced to each other. By coming up with a reduction between these two problems
we automatically gain new algorithms for solving both these problems.
In addition we present new bayesian methods for solving the knowledge base
completion problem based on stochastic block models.

\section{Background}
\label{sec:background}
\subsection{Knowledge Graphs}
\label{sec:knowledge-graphs}
\alert{One of the chracteristics of Knowledge graphs is that because of their
  hierarchical structure they tend to be sparse. For example, the number of
  edges in a forest can only grow $O(n)$}

\todo{Automated Question Answering, Freebase, Incompleteness of Knowledge Bases, seed based information extraction vs Knowledge Base Completion}

\todo{Algorithms for KBC, class instance acquisition}
\subsection{Communication Graphs}
\label{sec:communication-graphs}
\todo{analysis of friendship networks, call logs for community detection, p2p graphs where vertices directly communicate with each other and there are no hubs and spokes}

\todo{SBM based methods.}


\subsection{Web Ontology Language (OWL)}
\label{sec:web-ontol-lang}


\section{Task Definition}
\subsection{sec:task}
A detailed knowledge graph about events, entities and relations amongst those
entities, such as that produced by the Rich ERE annotations, can be a useful
dataset. The challenge, after we have produced such a dataset, is that what can
we do with it?

In order to guide ourselves to more relevant and interesting research we need to first make hypotheses about the use cases for such a dataset. One of the most important use cases for such a dataset is that we can create ``infoboxes'' about entities and events using such databases. Selecting what should go into those infoboxes is a difficult problem. A structured database can also be useful for testing the validity of assertions. For example we may want to ascertain the probability of truth of a statement like, ``Osama bin laden lives in pakistan''. We can use methods similar to PRA to determine whether
OBL really lives in pakistan based on the path between OBL and pakistan and check whether a path like that exists between other entities and locations that they reside in.
In order to figure out what

One basic question of this type would be what is the ``canonicalString'' of a
\begin{enumerate}
\item
\end{enumerate}


\section{Edge Prediction for Vertex Label Prediction}
\label{sec:edge-for-vertex}
Consider a simple case where we are given a graph $G = (V, E)$.
Let $f$ be a map from $V$ to ${0, 1}$ that is partially observed on $S \subset V$.
In this simplified case of vertex label prediction we have to rank the vertices in $V-S$
in such an order that those vertices that $f$ assigns a value of one to, appear higher up in the
ranking.\footnote{If $f$ could be arbitrary then any prediction rule that we come up with could be
forced to have accuracy zero on the test set.}

\newthought{One of the existing methods} for vertex nomination rests on the assumption that $f$ can be
modeled through a stochastic block model~\cite{fishkind2015vertex}.

\newthought{The SBM can be exploited} thought the use of a modularity based method.
Consider the NG modularity, it can be minimized to get an assignment of vertices to
blocks. Once the block assignments are known then the vertices class connection matrix
can be estimated and the class connection matrix and the block assignments together
give us a method to rank vertices.

\newthought{Another method for vertex nomination} is MAD~\cite{talukdar2009new}.
This algorithm tries to minimize the following objective.
\begin{itemize}
\item For labeled vertices we want the output of the algorithm to be close to a-priori given labels. \ie{} $Y_v \simeq \hat{Y_v}$.
\item For pairs of vertices that are close according to the input graph, we would like their labeling to be close. \ie{} $\hat{Y}_u \simeq \hat{Y}_v$ if $W_{uv}$ is large.
\item Third we want the output to be as uninformative as possible.
\end{itemize}
The objective can be written as:
$$ \sum_{v} w_v || y_v - \hat{y}_v ||^2 + \sum_l ||\hat{y}_l - R_l ||^2 + \sum_l \hat{Y}_l^\intercal L \hat{Y}_l $$

\newthought{The RESCAL method for KBC} can be utilized for vertex nomination
as follows: first we introduce two dummy nodes and connect vertices in $S$
to these dummy nodes according to the observed labeling. Then we use the RESCAL
method to predict how strongly the vertices in $V-S$ are connected to these two
dummy nodes. We can use the difference between these two affinities to rank the
vertices and thereby produce a nomination list.


\section{Experiments}
\label{sec:experiments}
\subsection{RESCAL Experiment}
\label{sec:simple-experiment}
In this experiment we produce a random SBM graph with 100 vertices and
2 hidden classes, called $C_0, C_1$. Let $V(C_0) \subset V$
be the vertices belonging to class $C_0$ and let $V(C_1)$ be defined
analogously. We select $C_1$ to be the ``desirable class''
I.e. the map $f$ outputs $1$ for vertices in $V(C_1)$
and it outputs $0$ for vertices in $V(C_0)$.
Then we sample equal number of vertices randomly from $V(C_0)$ and $V(C_1)$
to create our set $S$ of vertices whose class labels we know.
Then we add two dummy nodes $D_0, D_1$ to $G$ and connect
the vertices in $V(C_0) \cap S \mapsto D_0$ and
vertices in $V(C_1) \cap S \mapsto D_1$.
Then we perform \textit{RESCAL} on this graph.
For performing \textit{RESCAL} we need to provide the algorithm
the graph and positive and negative example.
The positive examples are the connections of $V(C_0) \cap S \mapsto D_0$
and $V(C_1) \cap S \mapsto D_1$. The negative example are the
wrong connections $V(C_0) \cap S \mapsto D_1$ and $V(C_1) \cap S \mapsto D_0$.
After training we can use the method to predict the affinity of vertices
in $V/S$ to connect to $D_1$ and $D_0$ and substract these two affinities
to get a ranked list.

We would expect that vertices belonging to $C_1$ would mostly appear before the
vertices belonging to $C_0$. To test this we can count the number of times
members of class $C_1$ appear in the top 50 members in the ranked list.
\pagebreak
\begin{table}[htbp]
  \begin{tabular}{l c c c c c}
    $B$ & 50 $\times$ P@50 & P@1 & P@5 & P@10 & P@50 \\ \toprule
  $\begin{bmatrix} 0.55 & 0.50 \\0.50 &0.55 \end{bmatrix}$ & 29 & 0.0 & 0.4 & 0.5 & 0.6 \\
  $\begin{bmatrix} 0.60 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 23 & 1.0 & 0.4 & 0.6 & 0.5 \\
  $\begin{bmatrix} 0.70 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 48 & 1.0 & 1.0 & 0.9 & 1.0 \\
  \end{tabular}
  \caption{Performance vs B Matrix. RESCAL Algorithm. Seed=0, Directed, Training Size=20}
  \label{tab:perf-vs-b-1}
\end{table}

\begin{table}[htbp]
  \begin{tabular}{l c c c c c}
    $B$ & 50 $\times$ P@50 & P@1 & P@5 & P@10 & P@50 \\ \toprule
  $\begin{bmatrix} 0.55 & 0.50 \\0.50 &0.55 \end{bmatrix}$ & 27 & 1.0 & 0.8 & 0.7 & 0.5 \\
  $\begin{bmatrix} 0.60 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 31 & 1.0 & 0.8 & 0.8 & 0.6 \\
  $\begin{bmatrix} 0.70 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 48 & 1.0 & 0.8 & 0.9 & 1.0 \\
  \end{tabular}
  \caption{Performance vs B Matrix. RESCAL Algorithm. Seed=1234, Directed, Training Size=20}
  \label{tab:perf-vs-b-2}
\end{table}

\begin{table}[htbp]
  \begin{tabular}{l c c c c c}
    $B$ & 50 $\times$ P@50 & P@1 & P@5 & P@10 & P@50 \\ \toprule
  $\begin{bmatrix} 0.55 & 0.50 \\0.50 &0.55 \end{bmatrix}$ & 28 & 0.0 & 0.6 & 0.7 & 0.6 \\
  $\begin{bmatrix} 0.60 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 35 & 1.0 & 1.0 & 1.0 & 0.7 \\
  $\begin{bmatrix} 0.70 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 39 & 1.0 & 1.0 & 1.0 & 0.8 \\
  \end{tabular}
  \caption{Performance vs B Matrix. RESCAL Algorithm. Seed=0, Undirected, Training Size=20}
  \label{tab:perf-vs-b-3}
\end{table}

\begin{table}[!htbp]
  \begin{tabular}{l c c c c c}
    $B$ & 50 $\times$ P@50 & P@1 & P@5 & P@10 & P@50 \\ \toprule
  $\begin{bmatrix} 0.55 & 0.50 \\0.50 &0.55 \end{bmatrix}$ & 29 & 1.0 & 1.0 & 0.8 & 0.6 \\
  $\begin{bmatrix} 0.60 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 30 & 0.0 & 0.8 & 0.8 & 0.6 \\
  $\begin{bmatrix} 0.70 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 37 & 1.0 & 1.0 & 1.0 & 0.7 \\
  \end{tabular}
\caption{Performance vs B Matrix. RESCAL Algorithm. Seed=1234, Undirected, Training Size=20}
\label{tab:perf-vs-b}
\end{table}

\pagebreak
\subsection{MAD Experiment}
\label{sec:mad-experiment}
\begin{table}[htbp]
  \begin{tabular}{l c c c c c}
    $B$ & 50 $\times$ P@50 & P@1 & P@5 & P@10 & P@50 \\ \toprule
  $\begin{bmatrix} 0.55 & 0.50 \\0.50 &0.55 \end{bmatrix}$ & 31 & 1.0 & 0.8 & 0.7 & 0.6 \\
  $\begin{bmatrix} 0.60 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 30 & 1.0 & 1.0 & 0.8 & 0.6 \\
  $\begin{bmatrix} 0.70 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 36 & 1.0 & 1.0 & 1.0 & 0.7 \\
  \end{tabular}
  \caption{Performance vs B Matrix. MAD Algorithm. Seed=0, Directed, Training Size=20}
  \label{tab:perf-vs-b-4}
\end{table}

\begin{table}[htbp]
  \begin{tabular}{l c c c c c}
    $B$ & 50 $\times$ P@50 & P@1 & P@5 & P@10 & P@50 \\ \toprule
  $\begin{bmatrix} 0.55 & 0.50 \\0.50 &0.55 \end{bmatrix}$ & 32 & 1.0 & 0.4 & 0.6 & 0.6 \\
  $\begin{bmatrix} 0.60 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 35 & 1.0 & 1.0 & 1.0 & 0.7 \\
  $\begin{bmatrix} 0.70 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 34 & 1.0 & 1.0 & 0.9 & 0.7 \\
  \end{tabular}
  \caption{Performance vs B Matrix. MAD Algorithm. Seed=1234, Directed, Training Size=20}
  \label{tab:perf-vs-b-5}
\end{table}

\begin{table}[htbp]
  \begin{tabular}{l c c c c c}
    $B$ & 50 $\times$ P@50 & P@1 & P@5 & P@10 & P@50 \\ \toprule
  $\begin{bmatrix} 0.55 & 0.50 \\0.50 &0.55 \end{bmatrix}$ & 27 & 1.0 & 0.8 & 0.8 & 0.5 \\
  $\begin{bmatrix} 0.60 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 30 & 1.0 & 1.0 & 0.9 & 0.6 \\
  $\begin{bmatrix} 0.70 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 32 & 1.0 & 0.8 & 0.9 & 0.6 \\
  \end{tabular}
  \caption{Performance vs B Matrix. MAD Algorithm. Seed=0, Undirected, Training Size=20}
  \label{tab:perf-vs-b-6}
\end{table}

\begin{table}[!htbp]
  \begin{tabular}{l c c c c c}
    $B$ & 50 $\times$ P@50 & P@1 & P@5 & P@10 & P@50 \\ \toprule
  $\begin{bmatrix} 0.55 & 0.50 \\0.50 &0.55 \end{bmatrix}$ & 28 & 1.0 & 0.8 & 0.7 & 0.6 \\
  $\begin{bmatrix} 0.60 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 31 & 0.0 & 0.6 & 0.7 & 0.6 \\
  $\begin{bmatrix} 0.70 & 0.50 \\0.50 &0.60 \end{bmatrix}$ & 32 & 1.0 & 1.0 & 0.9 & 0.6 \\
  \end{tabular}
  \caption{Performance vs B Matrix. MAD Algorithm. Seed=1234, Undirected, Training Size=20}
  \label{tab:perf-vs-b-7}
\end{table}

\pagebreak
\subsection{Presidents Collective Classification Dataset}
\label{sec:pres-coll-class}
\newthought{The US President Collective Classification Dataset} was
curated by~\cite{nickel2011three} by selecting US presidents, vice
presidents and their parties. The graph basically contains an edge
from vice presidents to presidents and every person is also labeled with
the political party that they were affiliated with.
\todo{Some of the persons were affiliated with more than one party
during their career, so its a multi-label prediction problem and not
 a vanilla multi-class classification problem. Right now I am just breaking ties
arbitrarily and removing multiple labels arbitrarily in the hopes that this wouldn't
be too bad since most people would have only one label. But we need to figure out
the right way to handle this.}

\newthought{Our goal with this dataset} is to compare the performance of
RESCAL, ASE and MAD:

\newthought{The RESCAL algorithm} takes in a series of sparse matrices, where each
matrix encodes a particular relation. \cite{nickel2011three} did a peculiar encoding
where they created two separate matrices for the \textit{president} and
\textit{vice-president} relations. We recreated there method and also compared with
the more \textit{sensible} approach where we combined these two relations into
a single matrix. Finally the metric for success was chosen to be Area under Precision-Recall
Curve. For a multi-label problem, with varying number of correct labels, this is the only reasonable metric.
P@K does not make sense for large K. We average all these numbers over 10 cross-val folds.

\newthought{The MAD algorithm} was designed for this kind of task and it also performs
just as well or infact better. \note{the MAD algorithm only allocates a few labels
to a node and the rest of the label allocations I do randomly. I don't think there
is any way to improve the situation.}

\newthought{The ASE Algorithm} for vertex nomination works by first embedding the nodes of a
graph. The training data assigns a few labels to each of these feature vectors, and we need to
learn a multi-class classifier. The most naive approach simply ignores the multi-label structure
of the problem, and instead randomly picks one of the labels in case there are multiple labels in
the training data. At test time, we also only predict one label, this label can be assigned the
highest rank and the other labels can be assigned ranks arbitrarily. If the test data mostly contains
nodes that only have one label then this is a reasonable approaximation to begin with.
\note{Most of the time this is a good assumption, the number of test nodes
  with multiple labels was 2 in 10 folds crossval.}
\note{Spectral method does not work. The graph is sparse, and no connected.
Clustering on the graph would not work. Dumbells}
What we really want is a general multi-label predictor.
\begin{table}
  \centering
  \begin{tabular}{l c c c c}
    Method           & AUPR & Avg-P@1 & \alert{Avg-P@5} & \alert{Avg-P@10} \\\toprule
    (0) RESCAL       & 0.76 & 0.74    & 0.16            & 0.09             \\
    RESCAL\_SENSIBLE & 0.74 & 0.71    & 0.16            & 0.09             \\
    \alert{ASE}      & 0.44 & 0.37    & 0.10            & 0.07             \\
    MAD              & 0.80 & 0.77    & 0.17            & 0.10             \\
    RANDOM           & 0.26 & 0.14    & 0.07            & 0.08             \\
    RANDOMWALK       & 0.79 & 0.76    & 0.18            & 0.11             \\\midrule
    (1234) RESCAL    & 0.79 & 0.77    & 0.17            & 0.09             \\
    RESCAL\_SENSIBLE & 0.77 & 0.75    & 0.17            & 0.09             \\
    \alert{ASE}      & 0.46 & 0.37    & 0.12            & 0.08             \\
    MAD              & 0.87 & 0.83    & 0.19            & 0.10             \\
    RANDOM           & 0.23 & 0.07    & 0.07            & 0.08             \\
    RANDOMWALK       & 0.86 & 0.80    & 0.20            & 0.11             \\\midrule
    (123) RESCAL     & 0.77 & 0.75    & 0.17            & 0.09             \\
    RESCAL\_SENSIBLE & 0.76 & 0.73    & 0.17            & 0.09             \\
    \alert{ASE}      & 0.47 & 0.38    & 0.12            & 0.08             \\
    MAD              & 0.81 & 0.78    & 0.18            & 0.09             \\
    RANDOM           & 0.22 & 0.07    & 0.07            & 0.08             \\
    RANDOMWALK       & 0.83 & 0.78    & 0.19            & 0.10             \\
  \end{tabular}
  \caption{Performance vs Algorithm On the US Presidents Dataset. The two sections are two monte-carlo runs.
    \alert{In this dataset P@5, P@10 don't make a lot of sense since there are only at most 1, 2 or 3 correct answers.}}
  \label{tab:perf-vs-algo-on-us-president}
\end{table}

\pagebreak
\subsection{Talukdar VN Data}
\label{sec:talukdar-vn-data}
\begin{table}[htbp]
  \centering
  \begin{tabular}{l c c c c}
    Method & AUPR & P@1 & P@5 & P@10 \\
    Rescal & \\
    ASE    & \\
    MAD    & \\
  \end{tabular}
  \caption{Performance vs Algorithm On Talukdar's Label Acquisition Dataset.}
  \label{tab:perf-vs-algo-on-label_acquisition}
\end{table}


\subsection{FB15K Experiment}
\label{sec:fb15k-experiment}
\note{The Fb15K dataset is an edge completion dataset. We can't really use it compare
the performance of VN algorithms, without approaching edge prediction as VN.}

\subsection{Modularity Experiment}
\label{sec:modul-exper}
\alert{TODO}

\clearpage
\subsection{Adept Experiment}
\label{sec:adept-experiment}
The Adept Dataset contained the following raw files.
\begin{table}[htbp]
  \centering
  \begin{tabular}{l rcl l }
    File Name  & Type      &    & Count     &                                                               \\\toprule
    Base       & (356004,  & 26 & , 389515) & (\alert{Event/Entity?}, attribute, attribute of event/entity) \\
    Ont-Type   & (356004,  & 1  & , 42)     & (\alert{Event/Entity?}, type, Event/Entity Type)              \\
    Metadata   & (352902,  & 1  & , 47796)  & (\alert{Event/Entity?}, appearsInDocument, docid)             \\
    Confidence & (1058707, & 5  & , 574678) & (XXX, XXX, XXX)                                               \\
    Other      & (1062276, & 14 & , 452)    & (XXX, XXX, XXX)                                               \\\bottomrule
  \end{tabular}
  \caption{The Adept Batch Dump.}
  \label{tab:adept-data}
\end{table}

Following is a map of entity type counts to the variant types. This map helped
my figure out what the columns in the RDF tables corresponded to.
\begin{table}[htbp]
  \centering
  \begin{tabular}{r l}
    26 & argument, canonicalMention, canonicalString, thing, timex2String, \\
       &  xsdDate, affiliatedEntity, child, crime, defendant, employeeMember, \\
       &  entity, founder, investorShareholder, leader, location, member, \\
       &  organization, parent, person, place, role, studentAlumni, \\
       &  subOrganization, time, url \\\midrule
    42 & base\#Date, base\#Entity, base\#Event, base\#GenericThing, \\
       &  base\#PredicateArgument, base\#Relation, base\#Thing, BeBorn,\\
       &  BusinessEvent, ChargeIndict, Crime, Die, EmploymentMembership,\\
       &  EndOrganization, FamilyRelationship, Founder, GeoPoliticalEntity,\\
       &  InterpersonalRelationship, InvestorShareholder, JusticeEvent,\\
       &  Leadership, LifeEvent, MemberOriginReligionEthnicity, Membership,\\
       &  Organization, OrganizationalAffiliation, OrganizationWebsite,\\
       &  OrgHeadquarter, Origin, ParentChildRelationship, PartWhole, Person,\\
       &  PhysicalLocation, Resident, Role, SiblingRelationship,\\
       &  SpousalRelationship, StartOrganization, StudentAlum,Subsidiary, Title,\\
       &  URL \\\midrule
    5  & confidence, object, predicate, subject, type \\\midrule
    14 & 22-rdf-syntax-ns\#type, rdf-schema\#domain, rdf-schema\#range,\\
       &  rdf-schema\#subClassOf, rdf-schema\#subPropertyOf, owl\#allValuesFrom,\\
       &  owl\#equivalentProperty, owl\#imports, owl\#maxQualifiedCardinality,\\
       &  owl\#minQualifiedCardinality, owl\#onClass, owl\#onDataRange,\\
       &  owl\#onProperty, owl\#qualifiedCardinality
  \end{tabular}
  \caption{Count to Variant Map}
  \label{tab:count-to-variant}
\end{table}

The edges and nodes in the Adept dataset can be classified into the following
categories
\begin{table}[htbp]
  \centering
  \begin{tabular}{l}
    \textbf{Types of Entities}\\\toprule
    Title\\
    URL\\
    Crime\\
    Person\\
    GeoPoliticalEntity\\
    Organization\\
  \end{tabular}
  \caption{Adept Node Types}
  \label{tab:adept-node-types}
\end{table}


\begin{table}[htbp]
  \centering
  \begin{tabular}{l l l}
 \textbf{Args} & \textbf{Relation/Event}       & \textbf{Argument Name}                            \\\toprule
 0             & OrganizationalAffiliation     &                                                   \\
 0             & PartWhole                     &                                                   \\
 1             & FamilyRelationship            & person (3508 = 417 + 1317 + 1774)                 \\
 1             & InterpersonalRelationship     & person (45999 = 3508 + 0 + 42491)                 \\
 1             & PhysicalLocation              & location (23530 = 0 + 7242 + 0 + 16288) \\
 2             & MemberOriginReligionEthnicity & person affiliatedEntity (2764 = 0 + 2764) \\
 2             & Subsidiary                    & parent subOrganization                            \\
 3             & BusinessEvent                 & time organization place                           \\
 3             & JusticeEvent                  & time crime place                                  \\
 3             & LifeEvent                     & time person place                                 \\\midrule
 1             & SiblingRelationship           & person (417)                                      \\
 1             & SpousalRelationship           & person (1317)                                     \\
 3             & BeBorn                        & time person place (1261)                          \\
 3             & EndOrganization               & time organization place (33)                      \\
 4             & StartOrganization             & agent time organization place (374)               \\
 6             & Die                           & victim time agent person instrument place (1612)  \\
               & \textbf{Total Unaccounted}    & $\mathbf{5014}$\\\midrule
 2             & EmploymentMembership          & employeeMember organization                       \\
 2             & Founder                       & founder organization                              \\
 2             & InvestorShareholder           & investorShareholder organization                  \\
 2             & Leadership                    & leader affiliatedEntity                           \\
 2             & OrganizationWebsite           & url organization                                  \\
 2             & OrgHeadquarter                & organization location                             \\
 2             & Origin                        & person affiliatedEntity                           \\
 2             & Resident                      & person location                                   \\
 2             & Role                          & role person                                       \\
 2             & StudentAlum                   & organization studentAlumni                        \\
 3             & ParentChildRelationship       & \textbf{parent} \textbf{child} \cmr{person}                               \\
 4             & Membership                    & \cmr{parent} \textbf{member} \textbf{organization} \cmr{subOrganization}        \\
 6             & ChargeIndict                  & \cmr{time} \textbf{defendant} \textbf{crime} \cmr{prosecutor} \cmr{adjudicator} \cmr{place} \\\bottomrule
  \end{tabular}
  \caption{Adept Dataset Categorization}
  \label{tab:adept-dataset-categ}
\end{table}

Out of the total data I only extracted the following:
\begin{table}[htbp]
  \centering
  \begin{tabular}{l l l l }
    \textbf{ID} & \textbf{Relation Name}  & \textbf{Arguments}                         & \textbf{Occurrence} \\\toprule
    1           & InvestorShareholder     & organization $\mapsto$ investorShareholder & $530$               \\
    2           & Origin                  & affiliatedEntity $\mapsto$ person          & $2764$              \\
    3           & EmploymentMembership    & organization $\mapsto$ employeeMember      & $36631$             \\
    4           & Membership              & organization $\mapsto$ member              & $369$               \\
    5           & OrgHeadquarter          & location $\mapsto$ organization            & $7242$              \\
    6           & Resident                & location $\mapsto$ person                  & $16288$             \\
    7           & OrganizationWebsite     & organization $\mapsto$ url                 & $200$               \\
    8           & ChargeIndict            & defendant $\mapsto$ crime                  & $387$               \\
    9           & Founder                 & organization $\mapsto$ founder             & $1281$              \\
    10          & Leadership              & leader $\mapsto$ affiliatedEntity          & $9600$              \\
    11          & Role                    & person $\mapsto$ role                      & $42491$             \\
    12          & StudentAlum             & organization $\mapsto$ studentAlumni       & $1306$              \\
    13          & ParentChildRelationship & parent $\mapsto$ child                     & $1774$              \\\midrule
                & \textbf{Total Nodes}          &                                            & $220603$ \\
                & \textbf{Total Edges}          &                                            & $120863$ \\\bottomrule
  \end{tabular}
  \caption{Extracted Nodes Summary}
  \label{tab:extraction-summary}
\end{table}


\subsection{Experiments on the Adept Data}
\label{sec:exper-adept-data}
The Adept Dataset contains 13 types of relations that connect 6 types of
entities. Unlike FreeBase this graph has been completely automatically
created and this. A processed version of this dataset contains 220603 nodes
and 120863 edges.

One of the problems with this dataset is that it is highly disconnected.
For example, the total number of components in this dataset are $150,338$
but in comparison the total number of nodes is only $220,603$. This suggests
that there are a large number of singleton edges in the KB and indeed we observe the following distribution of component sizes to number of components:
\begin{table}[htbp]
  \centering
  \begin{tabular}{l l l l}
\textbf{Component Size} & \textbf{Num Components} & \textbf{Node} & \\\toprule
1                       & 144832       &  144832 & 144832         \\
2                       & 4779         &  9558   & 154390         \\
3                       & 544          &  1632   & 156022         \\
4                       & 119          &  476    & 156498         \\
5                       & 30           &  150    & 156648         \\
6                       & 23           &  138    & 156786         \\
7                       & 8            &  56     & 156842         \\
10                      & 2            &  20     & 156862         \\
63741                   & 1            &  63741  & 220603 \\\bottomrule
  \end{tabular}
  \caption{Histogram of component sizes to number of components.}
\label{tab:hist-comp-size}
\end{table}
This distribution shows that $12,030$ vertices reside in clusters of sizes between
$10$ and $2$ and the rest of them lie inside a giant cluster of size $63,741$.

\newthought{Experiment Details:} Given the above described graph we will
perform the following experiment.
Consider a particular organization, say $O$. Say it contains $m$ members.
Pick $k = 5$ random subsets of size $m' = \lceil{m * p}$ where
$p \in [0.25, 0.5]$. Remove the edges connecting those $m'$ members to
$O$ but keep those $m'$ vertices in the graph and maintain their other edges.
This is a specific observation model where only the relations around one of
the members is missing.

Now rank the vertices $\mathcal{V}$ where $\mathcal{V}$ are the
vertices in the giant component and compute the rank of $m'$ members
amongst nodes that are people after removing the $\{m\} \setminus \{m'\}$
members from the ranking list. The goal is that the MRR and P@K of the $m'$
members should be high.

The methds of ranking the vertices are:
\begin{enumerate}
\item \textsc{Random Walk} In the random walk method, we perform
  $w$ random walks starting
  from the $\{m\} \setminus \{m'\}$ vertices of length $l$ and count how many
  times the random walks visit the vertices in the graph. We then assign the
  highest score to that node that was visited most often. The intuition is that
  vertices that are ``heavily'' connected to other vertices that have a particular
  label would also have that label.
  However in this KB, where \textit{type} connections abound the following happens:
  \begin{lstlisting}
    Organization:  "BART"
    Employees Removed "Jim Allison"
    Employees Kept "Alicia Trost" "Thomas Hock" "Tom Radulovich" "James K. Allison" "Rick Rice"
        Shortest path b/w org and employee BEFORE deletion: [[1]]
        Shortest path b/w org and employee AFTER deletion: [3]
           "BART" EmploymentMembership_organization_to_employeeMember -> Role_person_to_role -> Role_person_to_role_inv "Jim Allison"
            Most common hit "BART" "Tom Radulovich" "president" "Richard" "John Schlesinger"
    Employees Removed "Jim Allison"
    Employees Kept "Alicia Trost" "Thomas Hock" "Tom Radulovich" "James K. Allison" "Rick Rice"
        Shortest path b/w org and employee BEFORE deletion: [[1]]
        Shortest path b/w org and employee AFTER deletion: [3]
           "BART" EmploymentMembership_organization_to_employeeMember -> Role_person_to_role -> Role_person_to_role_inv "Jim Allison"
            Most common hit "BART" "Charles Johnston" "CNN" "Chris Danielsen" "Rick Rice"
    Employees Removed "James K. Allison"
    Employees Kept "Alicia Trost" "Thomas Hock" "Tom Radulovich" "Jim Allison" "Rick Rice"
        Shortest path b/w org and employee BEFORE deletion: [[1]]
        Shortest path b/w org and employee AFTER deletion: [3]
           "BART" EmploymentMembership_organization_to_employeeMember -> Role_person_to_role -> Role_person_to_role_inv "James K. Allison"
            Most common hit "BART" "analyst" "spokesman" "Germany" "Dieter Laser"
    Employees Removed "James K. Allison"
    Employees Kept "Alicia Trost" "Thomas Hock" "Tom Radulovich" "Jim Allison" "Rick Rice"
        Shortest path b/w org and employee BEFORE deletion: [[1]]
        Shortest path b/w org and employee AFTER deletion: [3]
           "BART" EmploymentMembership_organization_to_employeeMember -> Role_person_to_role -> Role_person_to_role_inv "James K. Allison"
            Most common hit "spokeswoman" "BART" "Alicia Trost" "Ford W. Bell" "Board"
    Employees Removed "Rick Rice"
    Employees Kept "Alicia Trost" "Thomas Hock" "Tom Radulovich" "Jim Allison" "James K. Allison"
        Shortest path b/w org and employee BEFORE deletion: [[1]]
        Shortest path b/w org and employee AFTER deletion: [3]
           "BART" EmploymentMembership_organization_to_employeeMember -> Role_person_to_role -> Role_person_to_role_inv "Rick Rice"
            Most common hit "Bay Area Rapid Transit" "MD Anderson Cancer Center" "BART" "James Strickland" "Thomas Hock"


  Organization:  "Arab League"
    Employees Removed "Kofi Annan"
    Employees Kept "Ken Paulson" "Nabil al- Araby" "Amr Moussa" "Lakhdar Brahimi" "Abdullah"
        Shortest path b/w org and employee BEFORE deletion: [[1]]
        Shortest path b/w org and employee AFTER deletion: [3]
           "Arab League" EmploymentMembership_organization_to_employeeMember -> Role_person_to_role -> Role_person_to_role_inv "Kofi Annan"
            Most common hit "Arab League" "journalist" "Oxford" "Chelsea Clinton" "Mom"
    Employees Removed "Lakhdar Brahimi"
    Employees Kept "Ken Paulson" "Nabil al- Araby" "Kofi Annan" "Amr Moussa" "Abdullah"
        Shortest path b/w org and employee BEFORE deletion: [[1]]
        Shortest path b/w org and employee AFTER deletion: [3]
           "Arab League" EmploymentMembership_organization_to_employeeMember -> Role_person_to_role -> Role_person_to_role_inv "Lakhdar Brahimi"
            Most common hit "Arab League" "Bill de Blasio" "American University" "Columbia" "Cairo"
    Employees Removed "Ken Paulson"
    Employees Kept "Nabil al- Araby" "Kofi Annan" "Amr Moussa" "Lakhdar Brahimi" "Abdullah"
        Shortest path b/w org and employee BEFORE deletion: [[1]]
        Shortest path b/w org and employee AFTER deletion: [4]
           "Arab League" OrgHeadquarter_location_to_organization_inv -> Resident_location_to_person -> Role_person_to_role -> Role_person_to_role_inv "Ken Paulson"
            Most common hit "Russian" "Arab League" "Jordan" "Scott Lively" "Kofi Annan"
    Employees Removed "Abdullah"
    Employees Kept "Ken Paulson" "Nabil al- Araby" "Kofi Annan" "Amr Moussa" "Lakhdar Brahimi"
        Shortest path b/w org and employee BEFORE deletion: [[1]]
        Shortest path b/w org and employee AFTER deletion: [3]
           "Arab League" Leadership_leader_to_affiliatedEntity_inv -> Origin_affiliatedEntity_to_person_inv -> Origin_affiliatedEntity_to_person "Abdullah"
            Most common hit "Arab League" "Queen" "Turkey" "Saken Zhasuzakov" "Hasan Emre Musluoglu"
    Employees Removed "Amr Moussa"
    Employees Kept "Ken Paulson" "Nabil al- Araby" "Kofi Annan" "Lakhdar Brahimi" "Abdullah"
        Shortest path b/w org and employee BEFORE deletion: [[1]]
        Shortest path b/w org and employee AFTER deletion: [3]
           "Arab League" Leadership_leader_to_affiliatedEntity_inv -> Role_person_to_role -> Role_person_to_role_inv "Amr Moussa"
            Most common hit "Arab League" "Syrian" "Dan Barwick" "President" "Jordan"
\end{lstlisting}

The following is the degree distribution of the graph:
\begin{verbatim}
[(0, 144832), (1, 41984), (2, 17535), (3, 6526), (4, 3222), (5, 1656),
 (6, 995), (7, 687), (8, 567), (9, 394), (10, 281), (11, 226),
 (12, 205), (13, 149), (14, 131), (15, 114), (16, 84), (17, 82),
 (18, 60), (19, 48), (20, 41), (21, 41), (22, 37), (23, 37),
 (24, 35), (25, 29), (26, 22), (27, 27), (28, 21), (29, 16),
 (30, 25), (31, 18), (32, 17), (33, 15), (34, 6), (35, 21),
 (36, 14), (37, 11), (38, 10), (39, 12), (40, 4), (41, 4),
 (42, 9), (43, 9), (44, 8), (45, 13), (46, 10), (47, 6),
 (48, 9), (49, 6), (50, 9), (51, 8), (52, 12), (53, 5),
 (54, 6), (55, 6), (56, 8), (57, 12), (58, 6), (59, 4),
 (60, 2), (61, 3), (62, 5), (63, 5), (64, 9), (65, 1),
 (67, 7), (68, 4), (69, 6), (71, 1), (72, 5), (73, 1),
 (74, 4), (75, 3), (76, 4), (77, 1), (78, 3), (79, 1),
 (80, 2), (81, 3), (82, 1), (84, 1), (85, 3), (86, 2),
 (87, 2), (88, 1), (89, 2), (92, 3), (93, 1), (94, 3),
 (95, 2), (96, 1), (97, 3), (98, 1), (99, 4), (101, 2),
 (102, 1), (103, 2), (104, 1), (105, 3), (106, 4), (108, 1),
 (109, 1), (110, 2), (111, 1), (112, 1), (113, 2), (114, 2),
 (116, 2), (117, 2), (118, 1), (121, 1), (123, 1), (124, 1),
 (126, 1), (127, 2), (128, 1), (129, 1), (132, 1), (133, 1),
 (135, 1), (136, 1), (137, 1), (138, 1), (139, 2), (141, 2),
 (143, 1), (149, 1), (150, 2), (159, 1), (160, 1), (164, 1),
 (173, 1), (174, 1), (179, 1), (187, 1), (195, 1), (203, 1),
 (204, 1), (206, 1), (215, 1), (219, 1), (220, 2), (221, 1),
 (224, 1), (228, 1), (232, 1), (236, 1), (239, 1), (243, 1),
 (245, 1), (249, 1), (251, 1), (261, 1), (267, 1), (281, 1),
 (282, 1), (291, 1), (294, 1), (298, 1), (300, 1), (305, 1),
 (335, 2), (340, 1), (351, 1), (359, 1), (364, 1), (369, 1),
 (378, 1), (403, 1), (416, 1), (451, 1), (458, 1), (475, 2),
 (520, 1), (524, 1), (562, 2), (579, 1), (594, 1), (606, 1),
 (630, 1), (714, 1), (717, 1), (743, 1), (818, 1), (861, 1),
 (902, 1), (905, 1), (1102, 1), (1906, 1), (2253, 1)]
\end{verbatim}

The most common generic types are:
\begin{verbatim}
director, president, professor
\end{verbatim}

\begin{table}[htbp]
  \centering
  \begin{tabular}{L L R L L L L L}
    &      & \multicolumn{5}{ c }{\text{Success Upper Bound}} & \\
 m  & p    & l=10  & l=30 & l=60 & l=120 & \text{ORGS Sampled} \\
 6  & 0.25 & 0.00  & 0.02 & 0.02 & 0.02 & 10 \\
 6  & 0.50 & 0.02  & 0.00 & 0.00 & 0.00 & 10 \\
 11 & 0.25 & 0.04  & 0.04 & 0.04 & 0.04 & 10 \\
 11 & 0.50 & 0.04  & 0.10 & 0.10 & 0.10 & 10 \\
 16 & 0.25 & 0.02  & 0.00 & 0.00 & 0.00 & 10 \\
 16 & 0.50 & 0.08  & 0.08 & 0.08 & 0.08 & 10 \\
 21 & 0.25 & 0.00  & 0.08 & 0.08 & 0.08 & 10 \\
 21 & 0.50 & 0.04  & 0.10 & 0.10 & 0.10 & 10 \\
 26 & 0.25 & 0.08  & 0.05 & 0.05 & 0.05 & 8  \\
 26 & 0.50 & 0.00  & 0.05 & 0.05 & 0.05 & 8  \\
 31 & 0.25 & 0.00  & 0.27 & 0.27 & 0.27 & 3  \\
 31 & 0.50 & 0.07  & 0.07 & 0.07 & 0.07 & 3  \\
 36 & 0.25 & 0.07  & 0.13 & 0.13 & 0.13 & 3  \\
 36 & 0.50 & 0.20  & 0.13 & 0.13 & 0.13 & 3  \\
 41 & 0.25 & 0.00  & 0.00 & 0.00 & 0.00 & 4  \\
 41 & 0.50 & 0.15  & 0.05 & 0.05 & 0.05 & 4  \\
 46 & 0.25 & 0.10  & 0.10 & 0.10 & 0.10 & 2  \\
 46 & 0.50 & 0.00  & 0.10 & 0.10 & 0.10 & 2  \\
  \end{tabular}
  \caption{caption}
  \label{tab:rw-performance}
\end{table}

Another discouraging fact is the histogram of shortest paths between employees
and their organizations after removal of the direct edge between them:
\begin{verbatim}
{2: 187, 3: 2654, 4: 292, 5: 575, 6: 5, 7: 11, 8: 3, 9: 1, inf: 607}
\end{verbatim}
\item \textsc{Rescal} \alert{TODO}
\item \textsc{Random Baseline} \alert{TODO}
\item \textsc{MAD} \alert{TODO}
\item \textsc{Ase} \alert{TODO}
\end{enumerate}

\alert{One interesting thing that pops out is the possibility to figure out
  common types by zoning in on the highly connected members of the KB}
\clearpage

\subsection{Questions About the Adept Data}
\label{sec:quest-about-adept}

\alert{Based on the above data the following questions come up}:
\begin{enumerate}
\item What is the first column in the files Base and Ont-Type? Do they contain
  the same type of things? Does it contain Event/Entity mentions in documents?
\item What is the first column on the Metadata table? If it is an
  \alert{Event/Entity} then why are there only $352902$ of them and not
  $356004$.
\item What does the confidence table contains?
\begin{verbatim}
$head -1 bbn_2016-02-23_13-09-09-confidence.nq
<http://www.w3.org/1999/02/22-rdf-syntax-ns#predicate> <http://www.w3.org/1999/02/22-rdf-syntax-ns#type> <http://www.w3.org/1999/02/22-rdf-syntax-ns#Property> .
\end{verbatim}
\alert{Why is \texttt{predicate} a \texttt{type} of \texttt{property}?}
\item What are the millions of enties in Confidence and Other tables?
\item Is it correct that the 3rd column of Other is just an expanded version of
  3rd column of Ont-Type?
\item What do the 2nd and 3rd columns of Other table signify ? More specifically
  what do the following combinations mean? What is subClassOf versus
  subPropertyOf? What is onClass versus onProperty?
\begin{verbatim}
</2000/01/rdf-schema#domain> </adept-base#Date>
</2000/01/rdf-schema#domain> </adept-base#ExternalID>
</2000/01/rdf-schema#domain> </1999/02/22-rdf-syntax-ns#List>
</2000/01/rdf-schema#domain> </1999/02/22-rdf-syntax-ns#Property>
</2000/01/rdf-schema#subClassOf> _:BX2D2ba1746fX3A152f52fd333X3AX2D7ee9
</2000/01/rdf-schema#subClassOf> _:BX2D2ba1746fX3A152f52fd333X3AX2D7eea
</2000/01/rdf-schema#subClassOf> </adept-core#Fine>
</2000/01/rdf-schema#subClassOf> </adept-core#Founder>
</2000/01/rdf-schema#subPropertyOf> </adept-core#destination>
</2000/01/rdf-schema#subPropertyOf> </adept-core#employeeMember>
</2002/07/owl#onClass> </adept-base#Entity>
</2002/07/owl#onClass> </adept-base#PredicateArgument>
</2002/07/owl#onProperty> </adept-core#crime>
</2002/07/owl#onProperty> </adept-core#defendant>
</2002/07/owl#qualifiedCardinality> "1"^^</2001/XMLSchema#integer>
\end{verbatim}

\end{enumerate}


\clearpage
\section{Future Work}
\label{sec:future-work}
A possible analysis of tensor factorization based methods for kbc, in the
original graph and the label augmented graph for the problem of vertex
clustering and the problem of edge prediction.

\bibliographystyle{plain}
\bibliography{vnschemes}
\end{document}

Work.
1. Run Random Walks.
3. Experiment on more datasets. FB@15K(Bordes), FB2SNAP(Neelakatnan), Presidents(Nickel), UMLS_Nations_Kinships(Kemp,Bordes)
   Presidents(Nickel)
   Label Acquisition(Talukdar)
   Kelvin()

We have to tie the procedure used to the graph.
FILL in the table, Talukdar and AdeptKB.

Do the Cohen's thing.


Random walk inference and learning in

We show that a soft inference procedure based on a combination of constrained
weighted, random walks.
