{\rtf1\ansi\ansicpg1252\cocoartf1038\cocoasubrtf360
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;\f1\fswiss\fcharset0 Helvetica;\f2\fnil\fcharset0 Menlo-Bold;
\f3\fnil\fcharset0 Monaco;}
{\colortbl;\red255\green255\blue255;\red156\green49\blue18;}
{\info
{\author Pushpendre}}\margl1440\margr1440\vieww27000\viewh20720\viewkind0
\deftab720
\pard\pardeftab720\ql\qnatural

\f0\fs24 \cf0 \'a0 \'a0- Papers that evaluate "Document Kernels"
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Using Centroids of Word Embeddings and Word Mover's Distance for Biomedical Document Retrieval in Question Answering
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Semantic Regularities in Document Representations.
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ News Citation Recommendation with Implicit and Explicit Semantics
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Short text similarity with word embeddings
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Learning to reweight terms with distributed representations
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ From word embeddings to document distances (WMD)
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ From word embeddings to document similarities for IR in software engineering
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Corpus-based and knowledge-based measures of text semantic similarity
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0 \'a0(Rada Mihalcea)
\f1 \

\f0 \'a0 \'a0 \'a0- Unsupervised Interpretable Topic Discovery.
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Toward Interpretable Topic Discovery via Anchored Correlation Explanation
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ The information sieve
\f1 \

\f0 \'a0 \'a0 \'a0- Similarity Between Trees
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Structured Lexical Similarity via Convolution Kernels on Dependency Trees
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Convolutional sentence kernel from word embeddings for short text categorization.
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ A Walk-based Semantically Enriched Tree Kernel Over Distributed Word Representations
\f1 \

\f0 \'a0 \'a0 \'a0- Theory
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Word embeddings as metric recovery in semantic spaces
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Nonparametric canonical correlation analysis
\f1 \

\f0 \'a0 \'a0 \'a0- Seminal Related Papers
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+\'a0Learning and Revising User Profiles: The Identification of Interesting Web Sites, Pazzani and Billsus (JML, 97)
\f1 \

\f0 \'a0 \'a0 \'a0- Learning from Positively Labeled - Unlabeled Examples
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+\'a0Cool Blog Classification from Positive and Unlabeled Examples
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+\'a0Learning to Classify Texts Using Positive and Unlabeled Data
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+\'a0PAC learning from positive statistical, queries. Denis (98) ALT-98
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+\'a0Learning with Positive and Unlabeled Examples Using, Weighted Logistic Regression
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Using Transductive inference for support vector machines
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0 \'a0Transductive inference for text classification using SVMs. Joachims
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ Using the unlabeled data to define a metric or a kernel function.
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0 \'a0Text categorization with labeled and unlabeled data: A generative model approach.\'a0
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0+ (Co Training) Using a partition of the set of features into two disjoint sets.\'a0
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0 \'a0Kamal Nigam, Rayid Ghani, Analyzing the applicability and effectiveness of co-training.
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0 \'a0Blum, Mitchell, Combining Labeled and Unlabeled Data with Co-training.
\f1 \

\f0 \'a0 \'a0 \'a0
\f2\b \cf2 - Document Routing
\f1\b0 \cf0 \

\f2\b \cf2 \'a0 \'a0 \'a0 \'a0This is the task that I am doing.
\f1\b0 \cf0 \

\f2\b \cf2 \'a0 \'a0 \'a0 \'a0+ 
\f0\b0 \cf0 A comparison on Classifiers and Document Representations for the Routing Problem, by Schutze et. al. says:
\f1 \

\f0 \'a0 \'a0 \'a0 \'a0 \'a0
\f1 Document routing can be described as a problem of statistical text classification.\'a0\
\'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0Documents are to be assigned to one of two categories, relevant or non-relevant,\'a0\
\'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0and a large sample of judged documents is available for training.\
\'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0\
\'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0This paper will compare traditional relevance feedback approaches to routing\
\'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0with classification based on explicit error minimization.\
\'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0\
\'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0 \'a0The central problem in routing is the high dimensionality of the native feature space.\
\pard\pardeftab720\ql\qnatural

\f3 \cf0 \'a0 \'a0 \'a0 \'a0+ Overview of the Sixth Text Retrieval Conference}